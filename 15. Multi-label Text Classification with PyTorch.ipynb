{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://stackabuse.com/python-for-nlp-developing-an-automatic-text-filler-using-n-grams/\n",
    "- https://github.com/shotapentaho/pytorch-sentiment-analysis/blob/master/5%20-%20Multi-class%20Sentiment%20Analysis.ipynb\n",
    "- https://github.com/keitakurita/practical-torchtext/blob/master/Lesson%201%20intro%20to%20torchtext%20with%20text%20classification.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torchtext import data\n",
    "\n",
    "SEED = 1234\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchtext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset can be downloaded from https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/overview\n",
    "\n",
    "toxic_comments = pd.read_csv(\"data/toxic_comments.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(toxic_comments.shape)\n",
    "\n",
    "toxic_comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter = toxic_comments[\"comment_text\"] != \"\"\n",
    "toxic_comments = toxic_comments[filter]\n",
    "toxic_comments = toxic_comments.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 8)\n"
     ]
    }
   ],
   "source": [
    "print(toxic_comments.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You should be fired, you're a moronic wimp who is too lazy to do research. It makes me sick that people like you exist in this world.\n"
     ]
    }
   ],
   "source": [
    "print(toxic_comments[\"comment_text\"][168])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toxic:1\n",
      "Severe_toxic:0\n",
      "Obscene:0\n",
      "Threat:0\n",
      "Insult:1\n",
      "Identity_hate:0\n"
     ]
    }
   ],
   "source": [
    "print(\"Toxic:\" + str(toxic_comments[\"toxic\"][168]))\n",
    "print(\"Severe_toxic:\" + str(toxic_comments[\"severe_toxic\"][168]))\n",
    "print(\"Obscene:\" + str(toxic_comments[\"obscene\"][168]))\n",
    "print(\"Threat:\" + str(toxic_comments[\"threat\"][168]))\n",
    "print(\"Insult:\" + str(toxic_comments[\"insult\"][168]))\n",
    "print(\"Identity_hate:\" + str(toxic_comments[\"identity_hate\"][168]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   toxic  severe_toxic  obscene  threat  insult  identity_hate\n",
       "0      0             0        0       0       0              0\n",
       "1      0             0        0       0       0              0\n",
       "2      0             0        0       0       0              0\n",
       "3      0             0        0       0       0              0\n",
       "4      0             0        0       0       0              0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic_comments_labels = toxic_comments[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]]\n",
    "toxic_comments_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f21d6a511d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = 10\n",
    "fig_size[1] = 8\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "\n",
    "toxic_comments_labels.sum(axis=0).plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(sen):\n",
    "    # Remove punctuations and numbers\n",
    "    sentence = re.sub('[^a-zA-Z]', ' ', sen)\n",
    "\n",
    "    # Single character removal\n",
    "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
    "\n",
    "    # Removing multiple spaces\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = []\n",
    "# sentences = list(toxic_comments[\"comment_text\"])\n",
    "# for sen in sentences:\n",
    "#     X.append(preprocess_text(sen))\n",
    "\n",
    "# y = toxic_comments_labels.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validate_test_split(df, train_percent=.6, validate_percent=.2, seed=None):\n",
    "    np.random.seed(seed)\n",
    "    perm = np.random.permutation(df.index)\n",
    "    m = len(df.index)\n",
    "    train_end = int(train_percent * m)\n",
    "    validate_end = int(validate_percent * m) + train_end\n",
    "    train = df.iloc[perm[:train_end]]\n",
    "    validate = df.iloc[perm[train_end:validate_end]]\n",
    "    test = df.iloc[perm[validate_end:]]\n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid, test = train_validate_test_split(toxic_comments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 8)\n",
      "(95742, 8)\n",
      "(31914, 8)\n",
      "(31915, 8)\n"
     ]
    }
   ],
   "source": [
    "print(toxic_comments.shape)\n",
    "print(train.shape)\n",
    "print(valid.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘data/toxic_comments’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir data/toxic_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"data/toxic_comments/train.csv\", index=False)\n",
    "valid.to_csv(\"data/toxic_comments/valid.csv\", index=False)\n",
    "test.to_csv(\"data/toxic_comments/test.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "spacy_en = spacy.load('en')\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda Status on system is False\n"
     ]
    }
   ],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "print(\"Cuda Status on system is {}\".format(is_cuda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample tokenizer which you can use\n",
    "def tokenizer(text):\n",
    "    return [tok for tok in nltk.word_tokenize(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = \"spacy\" uses spacy's tokenizer\n",
    "TEXT = data.Field(sequential=True, tokenize=\"spacy\", lower=True)\n",
    "LABEL = data.LabelField(dtype=torch.long, sequential=False, use_vocab=False)\n",
    "# LABEL = Field(sequential=False, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMMENT_TEXT = data.Field()\n",
    "# TOXIC = data.Field()\n",
    "# SEVERE_TOXIC = data.Field()\n",
    "# OBSCENE = data.Field()\n",
    "# THREAT = data.Field()\n",
    "# INSULT = data.Field()\n",
    "# IDENTITY_HATE = data.Field()\n",
    "\n",
    "# create tuples representing the columns\n",
    "fields = [(\"id\", None), # we won't be needing the id, so we pass in None as the field\n",
    "                 (\"comment_text\", TEXT), (\"toxic\", LABEL),\n",
    "                 (\"severe_toxic\", LABEL), (\"threat\", LABEL),\n",
    "                 (\"obscene\", LABEL), (\"insult\", LABEL),\n",
    "                 (\"identity_hate\", LABEL)]\n",
    "\n",
    "train_data, valid_data, test_data = data.TabularDataset.splits(\n",
    "    path=\"data/toxic_comments/\", train=\"train.csv\", \n",
    "    validation=\"valid.csv\", test=\"test.csv\",format=\"csv\", skip_header=True, \n",
    "#     fields=[('Text', TEXT), ('Label', LABEL)]\n",
    "    fields = fields\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 95742\n",
      "Number of valid examples: 31914\n",
      "Number of testing examples: 31915\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of training examples: {len(train_data)}')\n",
    "print(f'Number of valid examples: {len(valid_data)}')\n",
    "print(f'Number of testing examples: {len(test_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_VOCAB_SIZE = 25_000\n",
    "\n",
    "TEXT.build_vocab(train_data, \n",
    "                 max_size = MAX_VOCAB_SIZE, \n",
    "                 vectors = \"glove.6B.100d\", \n",
    "                 unk_init = torch.Tensor.normal_)\n",
    "\n",
    "LABEL.build_vocab(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'comment_text': ['changing',\n",
       "  'images',\n",
       "  '\\n\\n',\n",
       "  'hi',\n",
       "  ',',\n",
       "  'why',\n",
       "  'are',\n",
       "  'you',\n",
       "  'changing',\n",
       "  'my',\n",
       "  'image',\n",
       "  'tags',\n",
       "  '.',\n",
       "  'they',\n",
       "  'are',\n",
       "  'fairinunse',\n",
       "  ',',\n",
       "  'they',\n",
       "  'have',\n",
       "  'a',\n",
       "  'source',\n",
       "  'and',\n",
       "  'rationale',\n",
       "  'and',\n",
       "  'for',\n",
       "  'some',\n",
       "  'reason',\n",
       "  'your',\n",
       "  'deleting',\n",
       "  'them',\n",
       "  '.',\n",
       "  'why',\n",
       "  '?'],\n",
       " 'toxic': '0',\n",
       " 'severe_toxic': '0',\n",
       " 'threat': '0',\n",
       " 'obscene': '0',\n",
       " 'insult': '0',\n",
       " 'identity_hate': '0'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(train_data[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', 308155),\n",
       " ('the', 297317),\n",
       " (',', 283416),\n",
       " ('\"', 227155),\n",
       " ('to', 178243),\n",
       " ('i', 142587),\n",
       " ('of', 134490),\n",
       " ('and', 133939),\n",
       " ('you', 131966),\n",
       " ('a', 129103)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.freqs.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['examples', 'fields'])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['new', 'source', '\\n\\n']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0].comment_text[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE, \n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[torchtext.data.batch.Batch of size 64]\n",
       "\t[.comment_text]:[torch.LongTensor of size 295x64]\n",
       "\t[.toxic]:[torch.LongTensor of size 64]\n",
       "\t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       "\t[.threat]:[torch.LongTensor of size 64]\n",
       "\t[.obscene]:[torch.LongTensor of size 64]\n",
       "\t[.insult]:[torch.LongTensor of size 64]\n",
       "\t[.identity_hate]:[torch.LongTensor of size 64]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(train_iterator.__iter__()); batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['batch_size', 'dataset', 'fields', 'input_fields', 'target_fields', 'comment_text', 'toxic', 'severe_toxic', 'threat', 'obscene', 'insult', 'identity_hate'])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchWrapper:\n",
    "    def __init__(self, dl, x_var, y_vars):\n",
    "        self.dl, self.x_var, self.y_vars = dl, x_var, y_vars # we pass in the list of attributes for x and y\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for batch in self.dl:\n",
    "            x = getattr(batch, self.x_var) # we assume only one input in this wrapper\n",
    "            \n",
    "            if self.y_vars is not None: # we will concatenate y into a single tensor\n",
    "                y = torch.cat([getattr(batch, feat).unsqueeze(1) for feat in self.y_vars], dim=1).float()\n",
    "            else:\n",
    "                y = torch.zeros((1))\n",
    "\n",
    "            yield (x, y)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = BatchWrapper(train_iterator, \"comment_text\", [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"])\n",
    "valid_dl = BatchWrapper(valid_iterator, \"comment_text\", [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"])\n",
    "test_dl = BatchWrapper(test_iterator, \"comment_text\", [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  201,    19,  5675,  ...,     5,   140,     5],\n",
       "         [   17,    12,  2009,  ...,    25,   452,    84],\n",
       "         [    7,    20,    25,  ...,    70,   511, 23162],\n",
       "         ...,\n",
       "         [    1,     1,     1,  ...,     1,     1,     1],\n",
       "         [    1,     1,     1,  ...,     1,     1,     1],\n",
       "         [    1,     1,     1,  ...,     1,     1,     1]]),\n",
       " tensor([[0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [1., 1., 0., 1., 1., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 1., 1.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 1., 1., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 1., 1., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 1., 1., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 1., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 1., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.]]))"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(train_dl.__iter__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# class FastText(nn.Module):\n",
    "#     def __init__(self, vocab_size, embedding_dim, output_dim, pad_idx):\n",
    "        \n",
    "#         super().__init__()\n",
    "        \n",
    "#         self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
    "        \n",
    "#         self.fc = nn.Linear(embedding_dim, output_dim)\n",
    "        \n",
    "#     def forward(self, text):\n",
    "        \n",
    "#         #text = [sent len, batch size]\n",
    "        \n",
    "#         embedded = self.embedding(text)\n",
    "                \n",
    "#         #embedded = [sent len, batch size, emb dim]\n",
    "        \n",
    "#         embedded = embedded.permute(1, 0, 2)\n",
    "        \n",
    "#         #embedded = [batch size, sent len, emb dim]\n",
    "                                        \n",
    "#         return self.fc(embedded)\n",
    "\n",
    "class SimpleBiLSTMBaseline(nn.Module):\n",
    "    def __init__(self, hidden_dim, emb_dim=300,\n",
    "                 spatial_dropout=0.05, recurrent_dropout=0.1, num_linear=1):\n",
    "        super().__init__() # don't forget to call this!\n",
    "        self.embedding = nn.Embedding(len(TEXT.vocab), emb_dim)\n",
    "        self.encoder = nn.LSTM(emb_dim, hidden_dim, num_layers=1, dropout=recurrent_dropout)\n",
    "        self.linear_layers = []\n",
    "        for _ in range(num_linear - 1):\n",
    "            self.linear_layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "        self.linear_layers = nn.ModuleList(self.linear_layers)\n",
    "        self.predictor = nn.Linear(hidden_dim, 6)\n",
    "    \n",
    "    def forward(self, seq):\n",
    "        hdn, _ = self.encoder(self.embedding(seq))\n",
    "        feature = hdn[-1, :, :]\n",
    "        for layer in self.linear_layers:\n",
    "            feature = layer(feature)\n",
    "        preds = self.predictor(feature)\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25002"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TEXT.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT_DIM = len(TEXT.vocab)\n",
    "# EMBEDDING_DIM = 100\n",
    "# OUTPUT_DIM = 6\n",
    "# PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "# model = FastText(INPUT_DIM, EMBEDDING_DIM, OUTPUT_DIM, PAD_IDX)\n",
    "\n",
    "# opt = optim.Adam(model.parameters(), lr=1e-2)\n",
    "# loss_func = nn.BCEWithLogitsLoss()\n",
    "\n",
    "em_sz = 100\n",
    "nh = 500\n",
    "nl = 3\n",
    "model = SimpleBiLSTMBaseline(nh, emb_dim=em_sz); model\n",
    "\n",
    "opt = optim.Adam(model.parameters(), lr=1e-2)\n",
    "loss_func = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 3,707,206 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7364,  1.1356, -0.0090,  ..., -1.4841,  0.4219,  0.0943],\n",
       "        [ 0.3202,  1.4562, -1.4856,  ...,  0.2605, -0.1280,  0.2449],\n",
       "        [-0.3398,  0.2094,  0.4635,  ..., -0.2339,  0.4730, -0.0288],\n",
       "        ...,\n",
       "        [ 0.0441,  0.6655, -0.0255,  ..., -0.0296, -0.4612,  0.8184],\n",
       "        [ 0.3466, -0.4393, -0.5898,  ...,  0.4000, -0.4355, -0.8640],\n",
       "        [-0.5669,  0.7411, -0.4570,  ...,  0.1494, -0.1386, -0.0659]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pretrained_embeddings = TEXT.vocab.vectors\n",
    "\n",
    "# model.embedding.weight.data.copy_(pretrained_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "\n",
    "# model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "# model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.optim as optim\n",
    "\n",
    "# optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# model = model.to(device)\n",
    "# criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predictions = model(batch).squeeze(1)\n",
    "        \n",
    "        loss = criterion(predictions, batch.label)\n",
    "        \n",
    "        acc = binary_accuracy(predictions, batch.label)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            predictions = model(batch.text).squeeze(1)\n",
    "            \n",
    "            loss = criterion(predictions, batch.label)\n",
    "            \n",
    "            acc = binary_accuracy(predictions, batch.label)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1496 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 1/1496 [01:31<38:02:49, 91.62s/it]\u001b[A\n",
      "  0%|          | 2/1496 [02:57<37:15:14, 89.77s/it]\u001b[A\n",
      "  0%|          | 3/1496 [04:10<35:09:32, 84.78s/it]\u001b[A\n",
      "  0%|          | 4/1496 [05:11<32:15:08, 77.82s/it]\u001b[A\n",
      "  0%|          | 5/1496 [06:01<28:44:31, 69.40s/it]\u001b[A\n",
      "  0%|          | 6/1496 [06:55<26:45:54, 64.67s/it]\u001b[A\n",
      "  0%|          | 7/1496 [07:59<26:41:06, 64.52s/it]\u001b[A\n",
      "  1%|          | 8/1496 [09:04<26:46:03, 64.76s/it]\u001b[A\n",
      "  1%|          | 9/1496 [10:04<26:09:01, 63.31s/it]\u001b[A\n",
      "  1%|          | 10/1496 [10:11<19:10:32, 46.46s/it]\u001b[A\n",
      "  1%|          | 11/1496 [10:25<15:06:58, 36.65s/it]\u001b[A\n",
      "  1%|          | 12/1496 [10:38<12:07:50, 29.43s/it]\u001b[A\n",
      "  1%|          | 13/1496 [10:53<10:25:38, 25.31s/it]\u001b[A\n",
      "  1%|          | 14/1496 [11:09<9:12:47, 22.38s/it] \u001b[A\n",
      "  1%|          | 15/1496 [11:15<7:13:21, 17.56s/it]\u001b[A\n",
      "  1%|          | 16/1496 [11:24<6:06:44, 14.87s/it]\u001b[A\n",
      "  1%|          | 17/1496 [11:40<6:14:21, 15.19s/it]\u001b[A\n",
      "  1%|          | 18/1496 [11:51<5:44:21, 13.98s/it]\u001b[A\n",
      "  1%|▏         | 19/1496 [12:01<5:16:44, 12.87s/it]\u001b[A\n",
      "  1%|▏         | 20/1496 [12:12<4:58:43, 12.14s/it]\u001b[A\n",
      "  1%|▏         | 21/1496 [12:18<4:16:02, 10.42s/it]\u001b[A\n",
      "  1%|▏         | 22/1496 [12:28<4:13:14, 10.31s/it]\u001b[A\n",
      "  2%|▏         | 23/1496 [12:35<3:45:48,  9.20s/it]\u001b[A\n",
      "  2%|▏         | 24/1496 [12:44<3:44:31,  9.15s/it]\u001b[A\n",
      "  2%|▏         | 25/1496 [12:56<4:07:58, 10.11s/it]\u001b[A\n",
      "  2%|▏         | 26/1496 [13:04<3:51:11,  9.44s/it]\u001b[A\n",
      "  2%|▏         | 27/1496 [13:12<3:38:54,  8.94s/it]\u001b[A\n",
      "  2%|▏         | 28/1496 [13:22<3:46:42,  9.27s/it]\u001b[A\n",
      "  2%|▏         | 29/1496 [13:32<3:53:14,  9.54s/it]\u001b[A\n",
      "  2%|▏         | 30/1496 [13:41<3:53:57,  9.58s/it]\u001b[A\n",
      "  2%|▏         | 31/1496 [13:54<4:17:41, 10.55s/it]\u001b[A\n",
      "  2%|▏         | 32/1496 [14:02<3:58:01,  9.76s/it]\u001b[A\n",
      "  2%|▏         | 33/1496 [14:16<4:29:12, 11.04s/it]\u001b[A\n",
      "  2%|▏         | 34/1496 [14:33<5:08:44, 12.67s/it]\u001b[A\n",
      "  2%|▏         | 35/1496 [14:46<5:11:15, 12.78s/it]\u001b[A\n",
      "  2%|▏         | 36/1496 [15:02<5:33:00, 13.69s/it]\u001b[A\n",
      "  2%|▏         | 37/1496 [15:09<4:47:14, 11.81s/it]\u001b[A\n",
      "  3%|▎         | 38/1496 [15:15<4:05:54, 10.12s/it]\u001b[A\n",
      "  3%|▎         | 39/1496 [15:27<4:16:08, 10.55s/it]\u001b[A\n",
      "  3%|▎         | 40/1496 [15:35<3:56:23,  9.74s/it]\u001b[A\n",
      "  3%|▎         | 41/1496 [15:49<4:29:02, 11.09s/it]\u001b[A\n",
      "  3%|▎         | 42/1496 [15:54<3:44:26,  9.26s/it]\u001b[A\n",
      "  3%|▎         | 43/1496 [16:04<3:53:25,  9.64s/it]\u001b[A\n",
      "  3%|▎         | 44/1496 [16:18<4:20:43, 10.77s/it]\u001b[A\n",
      "  3%|▎         | 45/1496 [16:30<4:33:05, 11.29s/it]\u001b[A\n",
      "  3%|▎         | 46/1496 [16:43<4:42:00, 11.67s/it]\u001b[A\n",
      "  3%|▎         | 47/1496 [16:56<4:54:06, 12.18s/it]\u001b[A\n",
      "  3%|▎         | 48/1496 [17:02<4:06:57, 10.23s/it]\u001b[A\n",
      "  3%|▎         | 49/1496 [17:10<3:51:57,  9.62s/it]\u001b[A\n",
      "  3%|▎         | 50/1496 [17:22<4:05:16, 10.18s/it]\u001b[A\n",
      "  3%|▎         | 51/1496 [17:33<4:12:46, 10.50s/it]\u001b[A\n",
      "  3%|▎         | 52/1496 [17:43<4:14:04, 10.56s/it]\u001b[A\n",
      "  4%|▎         | 53/1496 [17:52<3:59:31,  9.96s/it]\u001b[A\n",
      "  4%|▎         | 54/1496 [17:58<3:29:42,  8.73s/it]\u001b[A\n",
      "  4%|▎         | 55/1496 [18:07<3:32:43,  8.86s/it]\u001b[A\n",
      "  4%|▎         | 56/1496 [18:12<3:07:13,  7.80s/it]\u001b[A\n",
      "  4%|▍         | 57/1496 [18:22<3:17:44,  8.24s/it]\u001b[A\n",
      "  4%|▍         | 58/1496 [18:32<3:35:29,  8.99s/it]\u001b[A\n",
      "  4%|▍         | 59/1496 [18:38<3:13:25,  8.08s/it]\u001b[A\n",
      "  4%|▍         | 60/1496 [18:44<2:56:00,  7.35s/it]\u001b[A\n",
      "  4%|▍         | 61/1496 [18:50<2:48:36,  7.05s/it]\u001b[A\n",
      "  4%|▍         | 62/1496 [18:59<3:01:40,  7.60s/it]\u001b[A\n",
      "  4%|▍         | 63/1496 [19:05<2:51:43,  7.19s/it]\u001b[A\n",
      "  4%|▍         | 64/1496 [19:13<2:56:37,  7.40s/it]\u001b[A\n",
      "  4%|▍         | 65/1496 [19:18<2:36:20,  6.56s/it]\u001b[A\n",
      "  4%|▍         | 66/1496 [19:23<2:28:45,  6.24s/it]\u001b[A\n",
      "  4%|▍         | 67/1496 [19:33<2:52:07,  7.23s/it]\u001b[A\n",
      "  5%|▍         | 68/1496 [19:41<2:57:55,  7.48s/it]\u001b[A\n",
      "  5%|▍         | 69/1496 [19:49<3:00:42,  7.60s/it]\u001b[A\n",
      "  5%|▍         | 70/1496 [19:59<3:16:49,  8.28s/it]\u001b[A\n",
      "  5%|▍         | 71/1496 [20:14<4:02:50, 10.22s/it]\u001b[A\n",
      "  5%|▍         | 72/1496 [20:18<3:19:47,  8.42s/it]\u001b[A\n",
      "  5%|▍         | 73/1496 [20:26<3:17:50,  8.34s/it]\u001b[A\n",
      "  5%|▍         | 74/1496 [20:30<2:48:50,  7.12s/it]\u001b[A\n",
      "  5%|▌         | 75/1496 [20:37<2:44:35,  6.95s/it]\u001b[A\n",
      "  5%|▌         | 76/1496 [20:42<2:31:48,  6.41s/it]\u001b[A\n",
      "  5%|▌         | 77/1496 [20:49<2:36:22,  6.61s/it]\u001b[A\n",
      "  5%|▌         | 78/1496 [20:53<2:21:09,  5.97s/it]\u001b[A\n",
      "  5%|▌         | 79/1496 [21:03<2:45:56,  7.03s/it]\u001b[A\n",
      "  5%|▌         | 80/1496 [21:11<2:55:24,  7.43s/it]\u001b[A\n",
      "  5%|▌         | 81/1496 [21:16<2:37:58,  6.70s/it]\u001b[A\n",
      "  5%|▌         | 82/1496 [21:26<2:58:27,  7.57s/it]\u001b[A\n",
      "  6%|▌         | 83/1496 [22:51<11:47:42, 30.05s/it]\u001b[A\n",
      "  6%|▌         | 84/1496 [23:15<11:23:18, 29.04s/it]\u001b[A\n",
      "  6%|▌         | 85/1496 [23:25<9:09:05, 23.35s/it] \u001b[A\n",
      "  6%|▌         | 86/1496 [23:35<7:35:05, 19.37s/it]\u001b[A\n",
      "  6%|▌         | 87/1496 [23:45<6:25:39, 16.42s/it]\u001b[A\n",
      "  6%|▌         | 88/1496 [23:50<5:03:26, 12.93s/it]\u001b[A\n",
      "  6%|▌         | 89/1496 [24:01<4:55:56, 12.62s/it]\u001b[A\n",
      "  6%|▌         | 90/1496 [24:11<4:33:43, 11.68s/it]\u001b[A\n",
      "  6%|▌         | 91/1496 [24:16<3:49:48,  9.81s/it]\u001b[A\n",
      "  6%|▌         | 92/1496 [24:23<3:25:56,  8.80s/it]\u001b[A\n",
      "  6%|▌         | 93/1496 [24:31<3:18:07,  8.47s/it]\u001b[A\n",
      "  6%|▋         | 94/1496 [24:38<3:09:34,  8.11s/it]\u001b[A\n",
      "  6%|▋         | 95/1496 [24:49<3:28:12,  8.92s/it]\u001b[A\n",
      "  6%|▋         | 96/1496 [24:57<3:22:00,  8.66s/it]\u001b[A\n",
      "  6%|▋         | 97/1496 [25:04<3:12:34,  8.26s/it]\u001b[A\n",
      "  7%|▋         | 98/1496 [25:12<3:11:35,  8.22s/it]\u001b[A\n",
      "  7%|▋         | 99/1496 [25:18<2:54:33,  7.50s/it]\u001b[A\n",
      "  7%|▋         | 100/1496 [25:25<2:49:58,  7.31s/it]\u001b[A\n",
      "  7%|▋         | 101/1496 [25:37<3:21:53,  8.68s/it]\u001b[A\n",
      "  7%|▋         | 102/1496 [25:46<3:22:58,  8.74s/it]\u001b[A\n",
      "  7%|▋         | 103/1496 [25:54<3:20:15,  8.63s/it]\u001b[A\n",
      "  7%|▋         | 104/1496 [26:06<3:43:01,  9.61s/it]\u001b[A\n",
      "  7%|▋         | 105/1496 [26:14<3:36:06,  9.32s/it]\u001b[A\n",
      "  7%|▋         | 106/1496 [26:23<3:31:29,  9.13s/it]\u001b[A\n",
      "  7%|▋         | 107/1496 [26:31<3:24:59,  8.86s/it]\u001b[A\n",
      "  7%|▋         | 108/1496 [26:37<3:00:25,  7.80s/it]\u001b[A\n",
      "  7%|▋         | 109/1496 [26:46<3:10:40,  8.25s/it]\u001b[A\n",
      "  7%|▋         | 110/1496 [26:50<2:44:03,  7.10s/it]\u001b[A\n",
      "  7%|▋         | 111/1496 [26:57<2:39:57,  6.93s/it]\u001b[A\n",
      "  7%|▋         | 112/1496 [27:05<2:49:47,  7.36s/it]\u001b[A\n",
      "  8%|▊         | 113/1496 [27:09<2:26:06,  6.34s/it]\u001b[A\n",
      "  8%|▊         | 114/1496 [27:15<2:18:40,  6.02s/it]\u001b[A\n",
      "  8%|▊         | 115/1496 [27:20<2:13:13,  5.79s/it]\u001b[A\n",
      "  8%|▊         | 116/1496 [27:27<2:22:10,  6.18s/it]\u001b[A"
     ]
    }
   ],
   "source": [
    "\n",
    "epochs = 2\n",
    "for epoch in range(1, epochs + 1):\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    model.train() # turn on training mode\n",
    "    for x, y in tqdm.tqdm(train_dl): # thanks to our wrapper, we can intuitively iterate over our data!\n",
    "        opt.zero_grad()\n",
    "\n",
    "        preds = model(x)\n",
    "        loss = loss_func(preds, y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "        running_loss += loss.item() * x.size(0)\n",
    "        \n",
    "    epoch_loss = running_loss / len(trn)\n",
    "    \n",
    "    # calculate the validation loss for this epoch\n",
    "    val_loss = 0.0\n",
    "    model.eval() # turn on evaluation mode\n",
    "    for x, y in valid_dl:\n",
    "        preds = model(x)\n",
    "        loss = loss_func(preds, y)\n",
    "        val_loss += loss.item() * x.size(0)\n",
    "\n",
    "    val_loss /= len(vld)\n",
    "    print('Epoch: {}, Training Loss: {:.4f}, Validation Loss: {:.4f}'.format(epoch, epoch_loss, val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-113-f3b9249d7826>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-110-e2bf2f5907c7>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "# N_EPOCHS = 2\n",
    "\n",
    "# best_valid_loss = float('inf')\n",
    "\n",
    "# for epoch in range(N_EPOCHS):\n",
    "\n",
    "#     start_time = time.time()\n",
    "    \n",
    "#     train_loss, train_acc = train(model, train_dl, optimizer, criterion)\n",
    "#     valid_loss, valid_acc = evaluate(model, valid_dl, criterion)\n",
    "    \n",
    "#     end_time = time.time()\n",
    "\n",
    "#     epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "#     if valid_loss < best_valid_loss:\n",
    "#         best_valid_loss = valid_loss\n",
    "#         torch.save(model.state_dict(), 'tut3-model.pt')\n",
    "    \n",
    "#     print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "#     print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "#     print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
