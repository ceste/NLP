{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Sentiment Analysis with LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5J_3JQsNmSn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cebc9f51-28c4-456d-87d4-e6224fd56a0c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skU3s27ONV_O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from string import punctuation\n",
        "from collections import Counter, OrderedDict\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torch import optim"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8y_4YP-NV_T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(text):\n",
        "    text = text.lower()\n",
        "    text = \"\".join([ch for ch in text if ch not in punctuation])\n",
        "    all_reviews = text.split(\"\\n\")\n",
        "#     text = \" \".join(text)\n",
        "    all_words = text.split()\n",
        "    \n",
        "    return all_reviews, all_words\n",
        "\n",
        "\n",
        "def pad_text(encoded_reviews, seq_length):\n",
        "    \n",
        "    reviews = []\n",
        "    \n",
        "    for review in encoded_reviews:        \n",
        "        if len(review) >= seq_length:\n",
        "            reviews.append(review[:seq_length])\n",
        "        else:\n",
        "            reviews.append([0]*(seq_length-len(review)) + review)\n",
        "        \n",
        "    return np.array(reviews)\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dhup5Z_8NV_X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "dec98050-d006-44e0-b489-918e61b76925"
      },
      "source": [
        "with open(\"/content/gdrive/My Drive/data/reviews.txt\") as f:\n",
        "    reviews = f.read()\n",
        "    \n",
        "print(len(reviews))\n",
        "    \n",
        "with open(\"/content/gdrive/My Drive/data/labels.txt\") as f:\n",
        "    labels = f.read()\n",
        "\n",
        "print(len(labels))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "33678267\n",
            "225000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niXtN-KTNV_c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_reviews, all_words = preprocess(reviews)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkajpgINNV_f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_counts = Counter(all_words)\n",
        "# word_list = sorted(word_counts, keys = word_counts.get, reverse = True)\n",
        "word_list = OrderedDict(word_counts.most_common())\n",
        "vocab_to_int = {word:idx+1 for idx, word in enumerate(word_list)}\n",
        "int_to_vocab = {idx:word for word, idx in vocab_to_int.items()}\n",
        "encoded_reviews = [[vocab_to_int[word] for word in review if word.strip()!='' ] for review in all_reviews]\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOQwTaAtNV_i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_labels = labels.split(\"\\n\")\n",
        "encoded_labels = [1 if label == \"positive\" else 0 for label in all_labels]\n",
        "assert len(encoded_reviews) == len(encoded_labels), \"# of encoded reivews & encoded labels must be the same!\""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YILJ-1CENV_m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "45172e2e-ca9e-4134-e91c-4e9d22a59636"
      },
      "source": [
        "len(encoded_reviews)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25001"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOuv81z-NV_q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ec9dd47f-1199-4a5c-b843-4d626125f74c"
      },
      "source": [
        "len(encoded_labels)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25001"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHDjJ7lzNV_v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoded_labels = np.array( [label for idx, label in enumerate(encoded_labels) if len(encoded_reviews[idx]) > 0] )\n",
        "encoded_reviews = [review for review in encoded_reviews if len(review) > 0]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFodskxXNV_z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8c011e08-1383-4db7-aae6-b76e164e1274"
      },
      "source": [
        "len(encoded_reviews)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBXNYUhcNV_2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ab91ac96-3b32-4d2b-e137-f47e3ca8e485"
      },
      "source": [
        "len(encoded_labels)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tW1lN2IhNV_5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b2babd4b-95aa-4759-ef49-66468a322dab"
      },
      "source": [
        "for idx, review in enumerate(encoded_reviews):\n",
        "    if len(review)<200:\n",
        "        print(idx)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "41\n",
            "165\n",
            "393\n",
            "439\n",
            "441\n",
            "460\n",
            "582\n",
            "593\n",
            "600\n",
            "638\n",
            "694\n",
            "747\n",
            "772\n",
            "833\n",
            "837\n",
            "859\n",
            "870\n",
            "897\n",
            "1026\n",
            "1059\n",
            "1093\n",
            "1305\n",
            "1308\n",
            "1319\n",
            "1342\n",
            "1484\n",
            "1488\n",
            "1541\n",
            "1542\n",
            "1621\n",
            "1714\n",
            "1733\n",
            "1794\n",
            "1838\n",
            "1868\n",
            "2130\n",
            "2137\n",
            "2329\n",
            "2360\n",
            "2410\n",
            "2418\n",
            "2433\n",
            "2444\n",
            "2598\n",
            "2666\n",
            "2671\n",
            "2714\n",
            "2929\n",
            "2992\n",
            "3466\n",
            "3504\n",
            "3505\n",
            "3542\n",
            "3744\n",
            "3759\n",
            "3836\n",
            "3895\n",
            "3899\n",
            "3910\n",
            "3965\n",
            "3969\n",
            "4020\n",
            "4053\n",
            "4122\n",
            "4150\n",
            "4154\n",
            "4161\n",
            "4262\n",
            "4274\n",
            "4321\n",
            "4333\n",
            "4335\n",
            "4434\n",
            "4506\n",
            "4570\n",
            "4573\n",
            "4615\n",
            "4703\n",
            "4721\n",
            "4766\n",
            "4784\n",
            "4853\n",
            "4872\n",
            "4918\n",
            "4958\n",
            "4998\n",
            "5050\n",
            "5126\n",
            "5128\n",
            "5130\n",
            "5193\n",
            "5229\n",
            "5297\n",
            "5324\n",
            "5380\n",
            "5496\n",
            "5500\n",
            "5509\n",
            "5559\n",
            "5561\n",
            "5572\n",
            "5574\n",
            "5639\n",
            "5802\n",
            "5857\n",
            "5961\n",
            "5962\n",
            "5964\n",
            "6115\n",
            "6127\n",
            "6159\n",
            "6173\n",
            "6210\n",
            "6226\n",
            "6228\n",
            "6236\n",
            "6238\n",
            "6267\n",
            "6354\n",
            "6464\n",
            "6495\n",
            "6548\n",
            "6568\n",
            "6628\n",
            "6825\n",
            "6897\n",
            "6917\n",
            "6953\n",
            "7242\n",
            "7358\n",
            "7362\n",
            "7374\n",
            "7451\n",
            "7524\n",
            "7636\n",
            "7638\n",
            "7640\n",
            "7644\n",
            "7804\n",
            "7806\n",
            "7815\n",
            "7915\n",
            "7959\n",
            "7963\n",
            "8020\n",
            "8059\n",
            "8185\n",
            "8191\n",
            "8262\n",
            "8394\n",
            "8450\n",
            "8452\n",
            "8553\n",
            "8560\n",
            "8709\n",
            "8721\n",
            "8724\n",
            "8742\n",
            "8770\n",
            "8890\n",
            "9266\n",
            "9294\n",
            "9304\n",
            "9338\n",
            "9360\n",
            "9516\n",
            "9558\n",
            "9567\n",
            "9599\n",
            "9756\n",
            "9789\n",
            "9886\n",
            "9898\n",
            "9906\n",
            "9992\n",
            "10008\n",
            "10047\n",
            "10119\n",
            "10142\n",
            "10223\n",
            "10323\n",
            "10369\n",
            "10399\n",
            "10477\n",
            "10542\n",
            "10582\n",
            "10594\n",
            "10680\n",
            "10711\n",
            "10764\n",
            "10824\n",
            "10844\n",
            "10998\n",
            "11091\n",
            "11103\n",
            "11166\n",
            "11182\n",
            "11368\n",
            "11406\n",
            "11468\n",
            "11469\n",
            "11470\n",
            "11471\n",
            "11475\n",
            "11521\n",
            "11530\n",
            "11564\n",
            "11636\n",
            "11770\n",
            "11800\n",
            "11865\n",
            "11900\n",
            "11956\n",
            "11980\n",
            "12048\n",
            "12066\n",
            "12113\n",
            "12115\n",
            "12163\n",
            "12224\n",
            "12230\n",
            "12232\n",
            "12272\n",
            "12313\n",
            "12351\n",
            "12355\n",
            "12488\n",
            "12613\n",
            "12678\n",
            "12697\n",
            "12701\n",
            "12749\n",
            "12816\n",
            "12832\n",
            "12834\n",
            "12942\n",
            "12946\n",
            "13045\n",
            "13059\n",
            "13200\n",
            "13308\n",
            "13585\n",
            "13634\n",
            "13695\n",
            "13797\n",
            "13950\n",
            "13973\n",
            "14022\n",
            "14112\n",
            "14141\n",
            "14196\n",
            "14200\n",
            "14229\n",
            "14387\n",
            "14436\n",
            "14452\n",
            "14485\n",
            "14572\n",
            "14615\n",
            "14625\n",
            "14651\n",
            "14770\n",
            "14801\n",
            "14814\n",
            "14919\n",
            "14983\n",
            "14987\n",
            "14991\n",
            "15128\n",
            "15229\n",
            "15272\n",
            "15650\n",
            "15670\n",
            "16042\n",
            "16146\n",
            "16339\n",
            "16378\n",
            "16584\n",
            "16600\n",
            "16677\n",
            "16710\n",
            "16786\n",
            "16817\n",
            "16823\n",
            "16835\n",
            "16836\n",
            "16878\n",
            "16884\n",
            "16936\n",
            "16976\n",
            "17054\n",
            "17060\n",
            "17066\n",
            "17135\n",
            "17648\n",
            "17830\n",
            "17832\n",
            "17885\n",
            "17980\n",
            "18007\n",
            "18096\n",
            "18109\n",
            "18112\n",
            "18154\n",
            "18237\n",
            "18253\n",
            "18337\n",
            "18419\n",
            "18551\n",
            "18567\n",
            "18620\n",
            "18708\n",
            "18785\n",
            "18867\n",
            "18873\n",
            "18916\n",
            "18928\n",
            "18975\n",
            "18985\n",
            "19104\n",
            "19125\n",
            "19198\n",
            "19228\n",
            "19304\n",
            "19320\n",
            "19328\n",
            "19343\n",
            "19352\n",
            "19365\n",
            "19395\n",
            "19611\n",
            "19663\n",
            "19808\n",
            "19966\n",
            "20082\n",
            "20091\n",
            "20130\n",
            "20140\n",
            "20284\n",
            "20288\n",
            "20377\n",
            "20429\n",
            "20734\n",
            "20813\n",
            "20844\n",
            "20857\n",
            "20900\n",
            "20959\n",
            "21131\n",
            "21202\n",
            "21282\n",
            "21370\n",
            "21544\n",
            "21601\n",
            "21632\n",
            "21656\n",
            "21715\n",
            "21717\n",
            "21721\n",
            "21746\n",
            "21748\n",
            "21842\n",
            "21851\n",
            "21879\n",
            "21929\n",
            "21934\n",
            "22138\n",
            "22140\n",
            "22144\n",
            "22219\n",
            "22278\n",
            "22304\n",
            "22314\n",
            "22498\n",
            "22715\n",
            "22755\n",
            "22768\n",
            "22788\n",
            "22825\n",
            "22994\n",
            "23045\n",
            "23049\n",
            "23054\n",
            "23295\n",
            "23434\n",
            "23437\n",
            "23514\n",
            "23610\n",
            "23645\n",
            "23842\n",
            "24002\n",
            "24004\n",
            "24037\n",
            "24057\n",
            "24073\n",
            "24105\n",
            "24219\n",
            "24248\n",
            "24286\n",
            "24387\n",
            "24454\n",
            "24612\n",
            "24672\n",
            "24728\n",
            "24781\n",
            "24798\n",
            "24873\n",
            "24892\n",
            "24949\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JI7NmzfNV_8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "11825bb6-dc6f-4f4c-cf76-b4a3065352b5"
      },
      "source": [
        "print(len(encoded_reviews[41]))\n",
        "print(encoded_reviews[41])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "85\n",
            "[23, 2035, 953, 1013, 2035, 3, 1348, 3, 1013, 23, 953, 1348, 13, 3, 1348, 953, 1166, 1802, 1498, 10, 1416, 953, 3, 511, 1498, 953, 3, 1802, 222, 23, 2035, 953, 13, 1013, 1348, 10, 1713, 23, 10, 13, 3, 2226, 1311, 1166, 1498, 10, 23, 13, 3, 2226, 3, 13, 23, 953, 709, 1311, 23, 2035, 953, 23, 3, 1498, 953, 1802, 23, 13, 709, 1311, 222, 953, 1802, 953, 1166, 1943, 953, 3, 1802, 222, 3, 1166, 23, 953, 1166, 10, 1498]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zql4QON8NV__",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "padded_reviews = pad_text(encoded_reviews, seq_length = 200)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CdSZ1VONWAC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "d329f028-d946-4c7e-9893-deabf4ee3cd0"
      },
      "source": [
        "print(len(padded_reviews[41]))\n",
        "print(padded_reviews[41])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "200\n",
            "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0   23 2035  953 1013 2035    3 1348    3 1013   23  953\n",
            " 1348   13    3 1348  953 1166 1802 1498   10 1416  953    3  511 1498\n",
            "  953    3 1802  222   23 2035  953   13 1013 1348   10 1713   23   10\n",
            "   13    3 2226 1311 1166 1498   10   23   13    3 2226    3   13   23\n",
            "  953  709 1311   23 2035  953   23    3 1498  953 1802   23   13  709\n",
            " 1311  222  953 1802  953 1166 1943  953    3 1802  222    3 1166   23\n",
            "  953 1166   10 1498]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRxlvvdANWAF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "711a150a-abae-46d5-ae94-d2740aaa2334"
      },
      "source": [
        "padded_reviews.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 200)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05dHKIm_NWAJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_ratio = 0.8\n",
        "valid_ratio = (1 - train_ratio)/2\n",
        "total = padded_reviews.shape[0]\n",
        "train_cutoff = int(total * train_ratio)\n",
        "valid_cutoff = int(total * (1 - valid_ratio))\n",
        "\n",
        "\n",
        "train_x, train_y = padded_reviews[:train_cutoff], encoded_labels[:train_cutoff]\n",
        "valid_x, valid_y = padded_reviews[train_cutoff : valid_cutoff], encoded_labels[train_cutoff : valid_cutoff]\n",
        "test_x, test_y = padded_reviews[valid_cutoff:], encoded_labels[valid_cutoff:]\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYxJ3ShaNWAL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = TensorDataset(torch.Tensor(train_x).long(), torch.Tensor(train_y).long())\n",
        "valid_data = TensorDataset(torch.Tensor(valid_x).long(), torch.Tensor(valid_y).long())\n",
        "test_data  = TensorDataset(torch.Tensor(test_x).long(), torch.Tensor(test_y).long())"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_tlJy4SNWAP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 50\n",
        "train_loader = DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
        "valid_loader = DataLoader(valid_data, batch_size = batch_size, shuffle = True)\n",
        "test_loader = DataLoader(test_data, batch_size = batch_size, shuffle = True)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgvbA1oYNWAS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SentimentLSTM(nn.Module):\n",
        "    \n",
        "    def __init__(self, n_vocab, n_embed, n_hidden, n_output, n_layers, drop_p = 0.5):\n",
        "        super().__init__()\n",
        "        # params: \"n_\" means dimension\n",
        "        self.n_vocab = n_vocab     # number of unique words in vocabulary\n",
        "        self.n_layers = n_layers   # number of LSTM layers \n",
        "        self.n_hidden = n_hidden   # number of hidden nodes in LSTM\n",
        "        \n",
        "        self.embedding = nn.Embedding(n_vocab, n_embed)\n",
        "        self.lstm = nn.LSTM(n_embed, n_hidden, n_layers, batch_first = True, dropout = drop_p)\n",
        "        self.dropout = nn.Dropout(drop_p)\n",
        "        self.fc = nn.Linear(n_hidden, n_output)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        \n",
        "        \n",
        "    def forward (self, input_words):\n",
        "                                             # INPUT   :  (batch_size, seq_length)\n",
        "        embedded_words = self.embedding(input_words)    # (batch_size, seq_length, n_embed)\n",
        "        lstm_out, h = self.lstm(embedded_words)         # (batch_size, seq_length, n_hidden)\n",
        "        lstm_out = self.dropout(lstm_out)\n",
        "        lstm_out = lstm_out.contiguous().view(-1, self.n_hidden) # (batch_size*seq_length, n_hidden)\n",
        "        fc_out = self.fc(lstm_out)                      # (batch_size*seq_length, n_output)\n",
        "        sigmoid_out = self.sigmoid(fc_out)              # (batch_size*seq_length, n_output)\n",
        "        sigmoid_out = sigmoid_out.view(batch_size, -1)  # (batch_size, seq_length*n_output)\n",
        "        \n",
        "        # extract the output of ONLY the LAST output of the LAST element of the sequence\n",
        "        sigmoid_last = sigmoid_out[:, -1]               # (batch_size, 1)\n",
        "        \n",
        "        return sigmoid_last, h\n",
        "    \n",
        "    \n",
        "    def init_hidden (self, batch_size):  # initialize hidden weights (h,c) to 0\n",
        "        \n",
        "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        weights = next(self.parameters()).data\n",
        "        h = (weights.new(self.n_layers, batch_size, self.n_hidden).zero_().to(device),\n",
        "             weights.new(self.n_layers, batch_size, self.n_hidden).zero_().to(device))\n",
        "        \n",
        "        \n",
        "        return h\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJWK1R7cNWAW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_vocab = len(vocab_to_int)\n",
        "n_embed = 400\n",
        "n_hidden = 512\n",
        "n_output = 1   # 1 (\"positive\") or 0 (\"negative\")\n",
        "n_layers = 2\n",
        "\n",
        "net = SentimentLSTM(n_vocab, n_embed, n_hidden, n_output, n_layers)\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr = 0.001)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "net = net.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kj9izlZ0NWAe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "86870232-f1f7-4bc0-9140-4b38fc7971c0"
      },
      "source": [
        "print_every = 100\n",
        "step = 0\n",
        "n_epochs = 4  # validation loss increases from ~ epoch 3 or 4\n",
        "clip = 5  # for gradient clip to prevent exploding gradient problem in LSTM/RNN\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    h = net.init_hidden(batch_size)\n",
        "    \n",
        "    for inputs, labels in train_loader:\n",
        "        step += 1\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        \n",
        "        # making requires_grad = False for the latest set of h\n",
        "        h = tuple([each.data for each in h])   \n",
        "        \n",
        "        \n",
        "        output, h = net(inputs)\n",
        "        loss = criterion(output.squeeze(), labels.float())\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
        "        optimizer.step()\n",
        "        \n",
        "        if (step % print_every) == 0:            \n",
        "            ######################\n",
        "            ##### VALIDATION #####\n",
        "            ######################\n",
        "            net.eval()\n",
        "            valid_losses = []\n",
        "            v_h = net.init_hidden(batch_size)\n",
        "            \n",
        "            for v_inputs, v_labels in valid_loader:\n",
        "                v_inputs, v_labels = inputs.to(device), labels.to(device)\n",
        "        \n",
        "                v_h = tuple([each.data for each in v_h])\n",
        "                \n",
        "                v_output, v_h = net(v_inputs)\n",
        "                v_loss = criterion(v_output.squeeze(), v_labels.float())\n",
        "                valid_losses.append(v_loss.item())\n",
        "\n",
        "            print(\"Epoch: {}/{}\".format((epoch+1), n_epochs),\n",
        "                  \"Step: {}\".format(step),\n",
        "                  \"Training Loss: {:.4f}\".format(loss.item()),\n",
        "                  \"Validation Loss: {:.4f}\".format(np.mean(valid_losses)))\n",
        "            net.train()\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/4 Step: 100 Training Loss: 0.6918 Validation Loss: 0.6891\n",
            "Epoch: 1/4 Step: 200 Training Loss: 0.7094 Validation Loss: 0.7006\n",
            "Epoch: 1/4 Step: 300 Training Loss: 0.6958 Validation Loss: 0.6926\n",
            "Epoch: 1/4 Step: 400 Training Loss: 0.6892 Validation Loss: 0.6876\n",
            "Epoch: 2/4 Step: 500 Training Loss: 0.6964 Validation Loss: 0.6987\n",
            "Epoch: 2/4 Step: 600 Training Loss: 0.6929 Validation Loss: 0.6897\n",
            "Epoch: 2/4 Step: 700 Training Loss: 0.6848 Validation Loss: 0.6846\n",
            "Epoch: 2/4 Step: 800 Training Loss: 0.6936 Validation Loss: 0.6903\n",
            "Epoch: 3/4 Step: 900 Training Loss: 0.6865 Validation Loss: 0.6903\n",
            "Epoch: 3/4 Step: 1000 Training Loss: 0.6926 Validation Loss: 0.6902\n",
            "Epoch: 3/4 Step: 1100 Training Loss: 0.6917 Validation Loss: 0.6900\n",
            "Epoch: 3/4 Step: 1200 Training Loss: 0.6822 Validation Loss: 0.6797\n",
            "Epoch: 4/4 Step: 1300 Training Loss: 0.6836 Validation Loss: 0.6924\n",
            "Epoch: 4/4 Step: 1400 Training Loss: 0.6836 Validation Loss: 0.6759\n",
            "Epoch: 4/4 Step: 1500 Training Loss: 0.6835 Validation Loss: 0.6753\n",
            "Epoch: 4/4 Step: 1600 Training Loss: 0.7099 Validation Loss: 0.6931\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcZGshnfNWAi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "39d242cd-8ac0-4e33-bba1-09f35077cee1"
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6m0PRD41NWAo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9c08dbe4-3a30-4c7b-a27a-cfeb108574e9"
      },
      "source": [
        "test_loader"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7fcfd7b429e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xrb23MjGNWAs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4f7e21e4-c52b-49e6-d5ec-3d2b6b75a18a"
      },
      "source": [
        "len(test_data)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2500"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enBdoCq-NWAz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fasVPMd2NWA2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}