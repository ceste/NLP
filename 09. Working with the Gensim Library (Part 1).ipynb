{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda install -c anaconda gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Dictionaries using In-Memory Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dictionary has: 46 tokens\n",
      "(AI),                    0\n",
      "AI                       1\n",
      "Computer                 2\n",
      "In                       3\n",
      "achieving                4\n",
      "actions                  5\n",
      "agents:                  6\n",
      "and                      7\n",
      "animals.                 8\n",
      "any                      9\n",
      "artificial              10\n",
      "as                      11\n",
      "by                      12\n",
      "called                  13\n",
      "chance                  14\n",
      "computer                15\n",
      "contrast                16\n",
      "defines                 17\n",
      "demonstrated            18\n",
      "device                  19\n",
      "displayed               20\n",
      "environment             21\n",
      "goals.                  22\n",
      "humans                  23\n",
      "in                      24\n",
      "intelligence            25\n",
      "intelligence,           26\n",
      "intelligent             27\n",
      "is                      28\n",
      "its                     29\n",
      "machine                 30\n",
      "machines,               31\n",
      "maximize                32\n",
      "natural                 33\n",
      "of                      34\n",
      "perceives               35\n",
      "research                36\n",
      "science                 37\n",
      "science,                38\n",
      "sometimes               39\n",
      "study                   40\n",
      "successfully            41\n",
      "takes                   42\n",
      "that                    43\n",
      "the                     44\n",
      "to                      45\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim import corpora\n",
    "from pprint import pprint\n",
    "\n",
    "text = [\"\"\"In computer science, artificial intelligence (AI),\n",
    "             sometimes called machine intelligence, is intelligence\n",
    "             demonstrated by machines, in contrast to the natural intelligence\n",
    "             displayed by humans and animals. Computer science defines\n",
    "             AI research as the study of intelligent agents: any device that\n",
    "             perceives its environment and takes actions that maximize its chance\n",
    "             of successfully achieving its goals.\"\"\"]\n",
    "\n",
    "tokens = [[token for token in sentence.split()] for sentence in text]\n",
    "gensim_dictionary = corpora.Dictionary(tokens)\n",
    "\n",
    "print(\"The dictionary has: \" +str(len(gensim_dictionary)) + \" tokens\")\n",
    "\n",
    "for k, v in gensim_dictionary.token2id.items():\n",
    "    print(f'{k:{15}} {v:{10}}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "print(gensim_dictionary.token2id[\"study\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "study\n"
     ]
    }
   ],
   "source": [
    "print(list(gensim_dictionary.token2id.keys())[list(gensim_dictionary.token2id.values()).index(40)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'(AI),': 0, 'AI': 1, 'Computer': 2, 'In': 3, 'achieving': 4, 'actions': 5, 'agents:': 6, 'and': 7, 'animals.': 8, 'any': 9, 'artificial': 10, 'as': 11, 'by': 12, 'called': 13, 'chance': 14, 'computer': 15, 'contrast': 16, 'defines': 17, 'demonstrated': 18, 'device': 19, 'displayed': 20, 'environment': 21, 'goals.': 22, 'humans': 23, 'in': 24, 'intelligence': 25, 'intelligence,': 26, 'intelligent': 27, 'is': 28, 'its': 29, 'machine': 30, 'machines,': 31, 'maximize': 32, 'natural': 33, 'of': 34, 'perceives': 35, 'research': 36, 'science': 37, 'science,': 38, 'sometimes': 39, 'study': 40, 'successfully': 41, 'takes': 42, 'that': 43, 'the': 44, 'to': 45}\n"
     ]
    }
   ],
   "source": [
    "print(gensim_dictionary.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dictionary has: 65 tokens\n",
      "{'(AI),': 0, 'AI': 1, 'Computer': 2, 'In': 3, 'achieving': 4, 'actions': 5, 'agents:': 6, 'and': 7, 'animals.': 8, 'any': 9, 'artificial': 10, 'as': 11, 'by': 12, 'called': 13, 'chance': 14, 'computer': 15, 'contrast': 16, 'defines': 17, 'demonstrated': 18, 'device': 19, 'displayed': 20, 'environment': 21, 'goals.': 22, 'humans': 23, 'in': 24, 'intelligence': 25, 'intelligence,': 26, 'intelligent': 27, 'is': 28, 'its': 29, 'machine': 30, 'machines,': 31, 'maximize': 32, 'natural': 33, 'of': 34, 'perceives': 35, 'research': 36, 'science': 37, 'science,': 38, 'sometimes': 39, 'study': 40, 'successfully': 41, 'takes': 42, 'that': 43, 'the': 44, 'to': 45, '\"artificial': 46, '\"cognitive\"': 47, '\"learning\"': 48, '\"problem': 49, 'Colloquially,': 50, 'associate': 51, 'describe': 52, 'functions': 53, 'human': 54, 'intelligence\"': 55, 'machines': 56, 'mimic': 57, 'minds,': 58, 'other': 59, 'solving': 60, 'such': 61, 'term': 62, 'used': 63, 'with': 64}\n"
     ]
    }
   ],
   "source": [
    "text = [\"\"\"Colloquially, the term \"artificial intelligence\" is used to\n",
    "           describe machines that mimic \"cognitive\" functions that humans\n",
    "           associate with other human minds, such as \"learning\" and \"problem solving\"\"\"]\n",
    "\n",
    "tokens = [[token for token in sentence.split()] for sentence in text]\n",
    "gensim_dictionary.add_documents(tokens)\n",
    "\n",
    "print(\"The dictionary has: \" + str(len(gensim_dictionary)) + \" tokens\")\n",
    "print(gensim_dictionary.token2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Dictionaries using Text Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'air': 0, 'also': 1, 'an': 2, 'and': 3, 'aspect': 4, 'average': 5, 'by': 6, 'caused': 7, 'change': 8, 'climate': 9, 'commonly': 10, 'continuing': 11, 'earlier': 12, 'earth': 13, 'economy': 14, 'effects': 15, 'emissions': 16, 'episodes': 17, 'experienced': 18, 'gasses': 19, 'geological': 20, 'global': 21, 'greenhouse': 22, 'in': 23, 'increase': 24, 'industrial': 25, 'is': 26, 'long': 27, 'mainly': 28, 'measurements': 29, 'modern': 30, 'multiple': 31, 'observed': 32, 'ocean': 33, 'of': 34, 'periods': 35, 'refers': 36, 'rise': 37, 'shown': 38, 'since': 39, 'system': 40, 'temperature': 41, 'temperatures': 42, 'term': 43, 'the': 44, 'though': 45, 'to': 46, 'warming': 47}\n"
     ]
    }
   ],
   "source": [
    "from gensim.utils import simple_preprocess\n",
    "from smart_open import smart_open\n",
    "import os\n",
    "\n",
    "gensim_dictionary = corpora.Dictionary(simple_preprocess(sentence, deacc=True) for sentence in open(r'data/file1.txt', encoding='utf-8'))\n",
    "\n",
    "print(gensim_dictionary.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'and': 0, 'are': 1, 'as': 2, 'both': 3, 'but': 4, 'by': 5, 'change': 6, 'changes': 7, 'climate': 8, 'commonly': 9, 'context': 10, 'differ': 11, 'effects': 12, 'global': 13, 'historical': 14, 'impacts': 15, 'in': 16, 'includes': 17, 'instrumental': 18, 'interchangeably': 19, 'its': 20, 'many': 21, 'millions': 22, 'modern': 23, 'observed': 24, 'of': 25, 'over': 26, 'paleoclimate': 27, 'precipitation': 28, 'proxy': 29, 'record': 30, 'records': 31, 'region': 32, 'since': 33, 'such': 34, 'temperature': 35, 'terms': 36, 'that': 37, 'the': 38, 'thousands': 39, 'to': 40, 'unprecedented': 41, 'used': 42, 'warming': 43, 'years': 44, 'air': 45, 'also': 46, 'an': 47, 'aspect': 48, 'average': 49, 'caused': 50, 'continuing': 51, 'earlier': 52, 'earth': 53, 'economy': 54, 'emissions': 55, 'episodes': 56, 'experienced': 57, 'gasses': 58, 'geological': 59, 'greenhouse': 60, 'increase': 61, 'industrial': 62, 'is': 63, 'long': 64, 'mainly': 65, 'measurements': 66, 'multiple': 67, 'ocean': 68, 'periods': 69, 'refers': 70, 'rise': 71, 'shown': 72, 'system': 73, 'temperatures': 74, 'term': 75, 'though': 76}\n"
     ]
    }
   ],
   "source": [
    "from gensim.utils import simple_preprocess\n",
    "from smart_open import smart_open\n",
    "import os\n",
    "\n",
    "class ReturnTokens(object):\n",
    "    def __init__(self, dir_path):\n",
    "        self.dir_path = dir_path\n",
    "\n",
    "    def __iter__(self):\n",
    "        for file_name in os.listdir(self.dir_path):            \n",
    "            if file_name.split('.')[-1]=='txt':\n",
    "                for sentence in open(os.path.join(self.dir_path, file_name), encoding='utf-8'):\n",
    "                    yield simple_preprocess(sentence)\n",
    "\n",
    "path_to_text_directory = r\"data\"\n",
    "gensim_dictionary = corpora.Dictionary(ReturnTokens(path_to_text_directory))\n",
    "\n",
    "print(gensim_dictionary.token2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Bag of Words Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Bag of Words Corpus from In-Memory Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 2), (8, 1), (9, 1), (10, 1), (11, 1), (12, 2), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 3), (26, 1), (27, 1), (28, 1), (29, 3), (30, 1), (31, 1), (32, 1), (33, 1), (34, 2), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 2), (44, 2), (45, 1)]]\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim import corpora\n",
    "from pprint import pprint\n",
    "\n",
    "text = [\"\"\"In computer science, artificial intelligence (AI),\n",
    "           sometimes called machine intelligence, is intelligence\n",
    "           demonstrated by machines, in contrast to the natural intelligence\n",
    "           displayed by humans and animals. Computer science defines\n",
    "           AI research as the study of intelligent agents: any device that\n",
    "           perceives its environment and takes actions that maximize its chance\n",
    "           of successfully achieving its goals.\"\"\"]\n",
    "\n",
    "tokens = [[token for token in sentence.split()] for sentence in text]\n",
    "\n",
    "gensim_dictionary = corpora.Dictionary()\n",
    "gensim_corpus = [gensim_dictionary.doc2bow(token, allow_update=True) for token in tokens]\n",
    "\n",
    "print(gensim_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('(AI),', 1), ('AI', 1), ('Computer', 1), ('In', 1), ('achieving', 1), ('actions', 1), ('agents:', 1), ('and', 2), ('animals.', 1), ('any', 1), ('artificial', 1), ('as', 1), ('by', 2), ('called', 1), ('chance', 1), ('computer', 1), ('contrast', 1), ('defines', 1), ('demonstrated', 1), ('device', 1), ('displayed', 1), ('environment', 1), ('goals.', 1), ('humans', 1), ('in', 1), ('intelligence', 3), ('intelligence,', 1), ('intelligent', 1), ('is', 1), ('its', 3), ('machine', 1), ('machines,', 1), ('maximize', 1), ('natural', 1), ('of', 2), ('perceives', 1), ('research', 1), ('science', 1), ('science,', 1), ('sometimes', 1), ('study', 1), ('successfully', 1), ('takes', 1), ('that', 2), ('the', 2), ('to', 1)]]\n"
     ]
    }
   ],
   "source": [
    "word_frequencies = [[(gensim_dictionary[id], frequence) for id, frequence in couple] for couple in gensim_corpus]\n",
    "print(word_frequencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Bag of Words Corpus from Text Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('air', 1), ('also', 1), ('an', 1), ('and', 3), ('aspect', 1), ('average', 2), ('by', 3), ('caused', 1), ('change', 1), ('climate', 2), ('commonly', 1), ('continuing', 1), ('earlier', 1), ('earth', 1), ('economy', 1), ('effects', 1), ('emissions', 1), ('episodes', 1), ('experienced', 1), ('gasses', 1), ('geological', 1), ('global', 1), ('greenhouse', 1), ('in', 3), ('increase', 1), ('industrial', 1), ('is', 1), ('long', 1), ('mainly', 1), ('measurements', 1), ('modern', 1), ('multiple', 1), ('observed', 1), ('ocean', 1), ('of', 5), ('periods', 1), ('refers', 1), ('rise', 1), ('shown', 1), ('since', 1), ('system', 1), ('temperature', 2), ('temperatures', 1), ('term', 2), ('the', 6), ('though', 1), ('to', 1), ('warming', 3)]]\n"
     ]
    }
   ],
   "source": [
    "from gensim.utils import simple_preprocess\n",
    "from smart_open import smart_open\n",
    "import os\n",
    "\n",
    "tokens = [simple_preprocess(sentence, deacc=True) for sentence in open(r'data/file1.txt', encoding='utf-8')]\n",
    "\n",
    "gensim_dictionary = corpora.Dictionary()\n",
    "gensim_corpus = [gensim_dictionary.doc2bow(token, allow_update=True) for token in tokens]\n",
    "word_frequencies = [[(gensim_dictionary[id], frequence) for id, frequence in couple] for couple in gensim_corpus]\n",
    "\n",
    "print(word_frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('and', 5), ('are', 2), ('as', 1), ('both', 1), ('but', 1), ('by', 1), ('change', 3), ('changes', 2), ('climate', 3), ('commonly', 1), ('context', 1), ('differ', 1), ('effects', 1), ('global', 2), ('historical', 1), ('impacts', 1), ('in', 3), ('includes', 1), ('instrumental', 1), ('interchangeably', 1), ('its', 1), ('many', 1), ('millions', 1), ('modern', 1), ('observed', 1), ('of', 3), ('over', 1), ('paleoclimate', 1), ('precipitation', 1), ('proxy', 1), ('record', 1), ('records', 1), ('region', 1), ('since', 1), ('such', 1), ('temperature', 1), ('terms', 1), ('that', 1), ('the', 5), ('thousands', 1), ('to', 2), ('unprecedented', 1), ('used', 1), ('warming', 3), ('years', 1)], [('and', 3), ('by', 3), ('change', 1), ('climate', 2), ('commonly', 1), ('effects', 1), ('global', 1), ('in', 3), ('modern', 1), ('observed', 1), ('of', 5), ('since', 1), ('temperature', 2), ('the', 6), ('to', 1), ('warming', 3), ('air', 1), ('also', 1), ('an', 1), ('aspect', 1), ('average', 2), ('caused', 1), ('continuing', 1), ('earlier', 1), ('earth', 1), ('economy', 1), ('emissions', 1), ('episodes', 1), ('experienced', 1), ('gasses', 1), ('geological', 1), ('greenhouse', 1), ('increase', 1), ('industrial', 1), ('is', 1), ('long', 1), ('mainly', 1), ('measurements', 1), ('multiple', 1), ('ocean', 1), ('periods', 1), ('refers', 1), ('rise', 1), ('shown', 1), ('system', 1), ('temperatures', 1), ('term', 2), ('though', 1)]]\n"
     ]
    }
   ],
   "source": [
    "from gensim.utils import simple_preprocess\n",
    "from smart_open import smart_open\n",
    "import os\n",
    "\n",
    "class ReturnTokens(object):\n",
    "    def __init__(self, dir_path):\n",
    "        self.dir_path = dir_path\n",
    "\n",
    "    def __iter__(self):\n",
    "        for file_name in os.listdir(self.dir_path):\n",
    "            if file_name.split('.')[-1]=='txt':\n",
    "                for sentence in open(os.path.join(self.dir_path, file_name), encoding='utf-8'):\n",
    "                    yield simple_preprocess(sentence)\n",
    "\n",
    "path_to_text_directory = r\"data\"\n",
    "\n",
    "gensim_dictionary = corpora.Dictionary()\n",
    "gensim_corpus = [gensim_dictionary.doc2bow(token, allow_update=True) for token in ReturnTokens(path_to_text_directory)]\n",
    "word_frequencies = [[(gensim_dictionary[id], frequence) for id, frequence in couple] for couple in gensim_corpus]\n",
    "\n",
    "print(word_frequencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating TF-IDF Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "Term frequency = (Frequency of the word in a document)/(Total words in the document)\n",
    "IDF(word) = Log((Total number of documents)/(Number of documents containing the word))\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Football', 0.35], ['I', 0.71], ['like', 0.35], ['play', 0.35], ['to', 0.35]]\n",
      "[['Football', 0.27], ['best', 0.53], ['game', 0.27], ['is', 0.53], ['the', 0.53]]\n",
      "[['like', 0.22], ['play', 0.22], ['to', 0.22], ['game', 0.22], ['?', 0.45], ['Which', 0.45], ['do', 0.45], ['you', 0.45]]\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim import corpora\n",
    "from pprint import pprint\n",
    "\n",
    "text = [\"I like to play Football\",\n",
    "       \"Football is the best game\",\n",
    "       \"Which game do you like to play ?\"]\n",
    "\n",
    "tokens = [[token for token in sentence.split()] for sentence in text]\n",
    "\n",
    "gensim_dictionary = corpora.Dictionary()\n",
    "gensim_corpus = [gensim_dictionary.doc2bow(token, allow_update=True) for token in tokens]\n",
    "\n",
    "from gensim import models\n",
    "import numpy as np\n",
    "\n",
    "tfidf = models.TfidfModel(gensim_corpus, smartirs='ntc')\n",
    "\n",
    "for sent in tfidf[gensim_corpus]:\n",
    "    print([[gensim_dictionary[id], np.around(frequency, decimals=2)] for id, frequency in sent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08109302162163289"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.2 * np.log(3/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08109302162163289"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1/5) * np.log(3/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading Built-In Gensim Models and Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 128.1/128.1MB downloaded\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "w2v_embedding = api.load(\"glove-wiki-gigaword-100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('honda', 0.8739858865737915),\n",
       " ('nissan', 0.8108116984367371),\n",
       " ('automaker', 0.7918164134025574),\n",
       " ('mazda', 0.7687169313430786),\n",
       " ('bmw', 0.7616021633148193),\n",
       " ('ford', 0.7547588348388672),\n",
       " ('motors', 0.7539199590682983),\n",
       " ('volkswagen', 0.7176680564880371),\n",
       " ('prius', 0.7156583070755005),\n",
       " ('chrysler', 0.7085399031639099)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_embedding.most_similar('toyota')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
